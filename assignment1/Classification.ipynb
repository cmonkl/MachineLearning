{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading data and exploring features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./stream_quality_data/train_data.csv')\n",
    "test_data = pd.read_csv('./stream_quality_data/test_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "report = ProfileReport(train_data)\n",
    "#report.to_file('./clf_report.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = train_data.drop('stream_quality', axis=1), train_data['stream_quality']\n",
    "X_test, y_test = test_data.drop('stream_quality', axis=1), test_data['stream_quality']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are categorical features that have to be encoded in order to use it in model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_columns = train_data.columns[train_data.dtypes == 'object']\n",
    "print('Categorical features: ', cat_columns.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# mapping categories to labels\n",
    "mapping = [{'col':'auto_bitrate_state', 'mapping':{'off':0, 'partial':1, 'full':2}},\n",
    "          {'col':'auto_fec_state', 'mapping':{'off':0, 'partial':1}}]\n",
    "\n",
    "encoder = OrdinalEncoder(mapping=mapping)\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(X_train.assign(target=y_train).corr())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is high positive correlation with fps_lags feature and negative correlation with fps_mean feature."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Automatic selection based on mutual information between features and target variable:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=8)\n",
    "\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "selected_feats = X_train.columns[selector.get_support()]\n",
    "print('Selected features with highest mutual inf: ', selected_feats.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selection based on importance of feature on performance of model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, RFE \n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=LogisticRegression(),\n",
    "    step=1,\n",
    "    cv=5,\n",
    "    min_features_to_select=2\n",
    ")\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "imp_cols = X_train.columns[rfecv.support_]\n",
    "print('Selected_features with rfecv: ',  imp_cols.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_clf_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics\n",
    "    :param y_true: ground truth labels\n",
    "    :param y_pred: predicted labels\n",
    "    :return: calculated metrics\n",
    "    \"\"\"\n",
    "    metrics = {'accuracy':accuracy_score(y_true, y_pred), \n",
    "              'precision':precision_score(y_true, y_pred),\n",
    "              'recall':recall_score(y_true, y_pred),\n",
    "              'f1':f1_score(y_true, y_pred)}\n",
    "    \n",
    "    return pd.Series(metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit_predict(model, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Function to fit model and get predictions\n",
    "    :param model: model to use\n",
    "    :param X_train: train data\n",
    "    :param y_train: target\n",
    "    :param X_test: test data\n",
    "    :return: predicted labels for train and test data\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)    \n",
    "    return y_pred_train, y_pred_test\n",
    "\n",
    "def print_metrics(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"\n",
    "    Function to get train and test metrics\n",
    "    :param y_train: train labels\n",
    "    :param y_pred_train: predicted labels\n",
    "    :param y_test: test labels\n",
    "    :param y_pred_test: predicted test labels\n",
    "    :return: DataFrame with test and train metrics\n",
    "    \"\"\"\n",
    "    train_metrics = get_clf_metrics(y_train, y_pred_train)\n",
    "    test_metrics = get_clf_metrics(y_test, y_pred_test)\n",
    "    return pd.concat([train_metrics, test_metrics], axis=1, keys=['train', 'test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_clf_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics\n",
    "    :param y_true: ground truth labels\n",
    "    :param y_pred: predicted labels\n",
    "    :return: calculated metrics\n",
    "    \"\"\"\n",
    "    metrics = {'accuracy':accuracy_score(y_true, y_pred), \n",
    "              'precision':precision_score(y_true, y_pred),\n",
    "              'recall':recall_score(y_true, y_pred),\n",
    "              'f1':f1_score(y_true, y_pred)}\n",
    "    \n",
    "    return pd.Series(metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training simple logistic regression model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "logreg = Pipeline([\n",
    "    ('preprocess', StandardScaler()), \n",
    "    ('model', LogisticRegression(penalty='none'))\n",
    "])\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg, X_train[imp_cols], y_train, X_test[imp_cols])\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "logreg_l2 = Pipeline([\n",
    "    ('preprocess', StandardScaler()), \n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_l2, \n",
    "                                 {'model__C':loguniform(1e-5, 1)}, \n",
    "                                 scoring='f1', \n",
    "                                 n_jobs=-1)\n",
    "\n",
    "search_tool.fit(X_train[imp_cols], y_train)\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "logreg_l2['model'].C = search_tool.best_params_['model__C']\n",
    "    \n",
    "y_pred_train, y_pred_test = fit_predict(logreg_l2, X_train[imp_cols], y_train, X_test[imp_cols])\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg_l1 = Pipeline([\n",
    "    ('preprocess', StandardScaler()), \n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l1\", solver=\"saga\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_l1, \n",
    "                                 {'model__C':loguniform(1e-5, 1)},\n",
    "                                 scoring='f1', \n",
    "                                 n_jobs=-1,\n",
    "                                 n_iter=10)\n",
    "search_tool.fit(X_train[imp_cols], y_train)\n",
    "logreg_l1['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_l1, X_train[imp_cols], y_train, X_test[imp_cols])\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg_poly = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, interaction_only=True)),\n",
    "    ('preprocess', StandardScaler()), \n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_poly, \n",
    "                                 {'model__C':loguniform(1e-5, 10)},\n",
    "                                 scoring='f1', \n",
    "                                 n_jobs=-1,\n",
    "                                 n_iter=10)\n",
    "search_tool.fit(X_train[imp_cols], y_train)\n",
    "logreg_poly['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_poly, X_train[imp_cols], y_train, X_test[imp_cols])\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outlier detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iqr = X_train[imp_cols].quantile(0.75) - X_train[imp_cols].quantile(0.25)\n",
    "up_bound = X_train[imp_cols].quantile(0.75) + iqr * 1.5\n",
    "low_bound = X_train[imp_cols].quantile(0.25) - iqr * 1.5\n",
    "outliers_mask = ((X_train[imp_cols] > up_bound) | (X_train[imp_cols] < low_bound)).sum(axis=1) > 0\n",
    "X_train_clean = X_train[~outliers_mask][imp_cols].copy()\n",
    "y_train_clean = y_train[~outliers_mask].copy()\n",
    "\n",
    "print('Percentage of outliers: ', 1 - X_train_clean.shape[0] / X_train.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "logreg_poly['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_poly, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Detecting outliers with interquantile range is not suitable in this case. There are many informative points dropped leading to poor performance. Perhaps the distribution of variables is too wide"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "outliers_mask = yhat == -1\n",
    "X_train_clean = X_train[~outliers_mask][imp_cols]\n",
    "y_train_clean = y_train[~outliers_mask]\n",
    "\n",
    "vals, counts = np.unique(yhat, return_counts=True)\n",
    "print('Percentage of outliers: ', counts[0] / train_data.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "logreg_poly['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_poly, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics show improvement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class imbalance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target labels data are highly imbalanced:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Class distribution: ')\n",
    "print(f'Class 1: {(y_train == 1).sum() / (y_train).count():f}')\n",
    "print(f'Class 0: {(y_train == 0).sum() / (y_train).count():f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform balancing of data by adding random observations from minority class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "oversample_tool = RandomOverSampler(sampling_strategy=0.35)\n",
    "X_over, y_over = oversample_tool.fit_resample(X_train_clean, y_train_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Class distribution after oversampling:')\n",
    "print(f'Class 1: {(y_over == 1).sum() / (y_over).count():f}')\n",
    "print(f'Class 0: {(y_over == 0).sum() / (y_over).count():f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate performance on new data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tool.fit(X_over, y_over)\n",
    "logreg_poly['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_poly, X_over, y_over, X_test[imp_cols])\n",
    "print_metrics(y_over, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as PipelineIm\n",
    "\n",
    "logreg_over = PipelineIm([\n",
    "    ('over', RandomOverSampler()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('preprocess', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_over, {'model__C':uniform(loc=1e-8, scale=1), \n",
    "                                               'over__sampling_strategy':uniform(loc=0.1, scale=1)},\n",
    "                                 scoring='f1')\n",
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "logreg_over['model'].C = search_tool.best_params_['model__C']\n",
    "logreg_over['over'].sampling_strategy = search_tool.best_params_['over__sampling_strategy']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print(\"Best parameter for sampling: \", search_tool.best_params_['over__sampling_strategy'])\n",
    "print(\"Best  cross validation f1 score: \",  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_over, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performance of the model has been improved"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Handling imbalanced data by randomly undersampling the majority class:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg_under = PipelineIm([\n",
    "    ('over', RandomOverSampler()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('preprocess', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_under, {'model__C':uniform(loc=1e-8, scale=1), \n",
    "                                               'over__sampling_strategy':uniform(loc=0.1, scale=1)},\n",
    "                                 scoring='f1')\n",
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "logreg_under['model'].C = search_tool.best_params_['model__C']\n",
    "logreg_under['over'].sampling_strategy = search_tool.best_params_['over__sampling_strategy']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print(\"Best parameter for sampling: \", search_tool.best_params_['over__sampling_strategy'])\n",
    "print(\"Best  cross validation f1 score: \",  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_under, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bbb8067",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: \n",
      "Class 1: 0.068460\n",
      "Class 0: 0.931540\n"
     ]
    }
   ],
   "source": [
    "print('Class distribution: ')\n",
    "print(f'Class 1: {(y_train == 1).sum() / (y_train).count():f}')\n",
    "print(f'Class 0: {(y_train == 0).sum() / (y_train).count():f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369984b1",
   "metadata": {},
   "source": [
    "Perform balancing of data by adding random observations from minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28c3405d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "oversample_tool = RandomOverSampler(sampling_strategy=0.35)\n",
    "X_over, y_over = oversample_tool.fit_resample(X_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88fee913",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling:\n",
      "Class 1: 0.259259\n",
      "Class 0: 0.740741\n"
     ]
    }
   ],
   "source": [
    "print('Class distribution after oversampling:')\n",
    "print(f'Class 1: {(y_over == 1).sum() / (y_over).count():f}')\n",
    "print(f'Class 0: {(y_over == 0).sum() / (y_over).count():f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6c797",
   "metadata": {},
   "source": [
    "Evaluate performance on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f069c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for C:  2.35506005866699\n",
      "Best  cross validation f1 score:  0.5760705664612442\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.826640</td>\n",
       "      <td>0.919715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.784687</td>\n",
       "      <td>0.384293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.456616</td>\n",
       "      <td>0.408755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.577298</td>\n",
       "      <td>0.396147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.826640  0.919715\n",
       "precision  0.784687  0.384293\n",
       "recall     0.456616  0.408755\n",
       "f1         0.577298  0.396147"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.fit(X_over, y_over)\n",
    "logreg_poly['model'].C = search_tool.best_params_['model__C']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print('Best  cross validation f1 score: ',  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_poly, X_over, y_over, X_test[imp_cols])\n",
    "print_metrics(y_over, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8125eedf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for C:  0.009342710156912187\n",
      "Best parameter for sampling:  0.3543567312102637\n",
      "Best  cross validation f1 score:  0.4394981800847999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.924645</td>\n",
       "      <td>0.920816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.430719</td>\n",
       "      <td>0.391080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.460650</td>\n",
       "      <td>0.411240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.445182</td>\n",
       "      <td>0.400907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.924645  0.920816\n",
       "precision  0.430719  0.391080\n",
       "recall     0.460650  0.411240\n",
       "f1         0.445182  0.400907"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as PipelineIm\n",
    "\n",
    "logreg_over = PipelineIm([\n",
    "    ('over', RandomOverSampler()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('preprocess', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_over, {'model__C':uniform(loc=1e-8, scale=1), \n",
    "                                               'over__sampling_strategy':uniform(loc=0.1, scale=1)},\n",
    "                                 scoring='f1')\n",
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "logreg_over['model'].C = search_tool.best_params_['model__C']\n",
    "logreg_over['over'].sampling_strategy = search_tool.best_params_['over__sampling_strategy']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print(\"Best parameter for sampling: \", search_tool.best_params_['over__sampling_strategy'])\n",
    "print(\"Best  cross validation f1 score: \",  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_over, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c464876f",
   "metadata": {},
   "source": [
    "The performance of the model has been improved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a989c63",
   "metadata": {},
   "source": [
    "Handling imbalanced data by randomly undersampling the majority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8322b3a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for C:  0.6800031692422369\n",
      "Best parameter for sampling:  0.3809611180929845\n",
      "Best  cross validation f1 score:  0.4387663215992485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.920110</td>\n",
       "      <td>0.916148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.409326</td>\n",
       "      <td>0.372177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.490460</td>\n",
       "      <td>0.438958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.446235</td>\n",
       "      <td>0.402818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.920110  0.916148\n",
       "precision  0.409326  0.372177\n",
       "recall     0.490460  0.438958\n",
       "f1         0.446235  0.402818"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_under = PipelineIm([\n",
    "    ('over', RandomOverSampler()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('preprocess', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=200, penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(logreg_under, {'model__C':uniform(loc=1e-8, scale=1), \n",
    "                                               'over__sampling_strategy':uniform(loc=0.1, scale=1)},\n",
    "                                 scoring='f1')\n",
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "logreg_under['model'].C = search_tool.best_params_['model__C']\n",
    "logreg_under['over'].sampling_strategy = search_tool.best_params_['over__sampling_strategy']\n",
    "print(\"Best parameter for C: \", search_tool.best_params_['model__C'])\n",
    "print(\"Best parameter for sampling: \", search_tool.best_params_['over__sampling_strategy'])\n",
    "print(\"Best  cross validation f1 score: \",  search_tool.best_score_)\n",
    "\n",
    "y_pred_train, y_pred_test = fit_predict(logreg_under, X_train_clean, y_train_clean, X_test[imp_cols])\n",
    "print_metrics(y_train_clean, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372194ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}