{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad45954",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read and display data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./bitrate_prediction/bitrate_train.csv')\n",
    "test_data = pd.read_csv('./bitrate_prediction/bitrate_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "report = ProfileReport(train_data)\n",
    "#report.to_file('./reg_report.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are no missing values. All the columns contain numerical data, no encoding is required."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = train_data.drop('target', axis=1), train_data['target']  \n",
    "X_test, y_test = test_data.drop('target', axis=1), test_data['target']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize data by projecting it to two dimensions with PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# scale features before PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train)\n",
    "\n",
    "model = PCA(0.95)\n",
    "projected = model.fit_transform(scaled_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Explained variance ratio')\n",
    "plt.bar(range(len(model.explained_variance_ratio_)), model.explained_variance_ratio_)\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('% Variance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Projection to principal component vectors does not help to save as much information as possible in the first components. This could mean unapplicability of the method or influence of some noise in the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interaction between first two component projections:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Projected data to first two PC')\n",
    "plt.scatter(projected[:, 0], projected[:, 1])\n",
    "plt.xlabel('First component')\n",
    "plt.ylabel('Second component')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scatter plot shows that some points in the projection are far from others which could imply presence of outliers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(train_data[['bitrate_mean', 'bitrate_std', 'fps_mean', 'fps_std', 'rtt_mean', 'target']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Correlation between features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(train_data.corr())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are features which have low correlation with target that can be excluded. Some features are highly correlated with each other and introduce multicollinearity to the regression problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropped frame related features have 97% of constant zero values and are not correlated with target, therefore we can remove them from consideration. On the other hand, bitrate_mean and bitrate_std features show high correlation with target variable as they describe the same thing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L1 regularized models give sparse coefficients which can be interpreted as their importance to the model. Unimportant features get 0 weight score. Feature selection with Lasso coefficients:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_selection_pipe = Pipeline([\n",
    "        ('preprocessing', StandardScaler()), \n",
    "        ('model', Lasso())\n",
    "])\n",
    "# train Linear Regression with l1 regularization\n",
    "feature_selection_pipe.fit(X_train, y_train)\n",
    "\n",
    "cols = X_train.columns\n",
    "weights = feature_selection_pipe['model'].coef_\n",
    "\n",
    "# visualize weights\n",
    "plt.bar(range(len(weights)), weights)\n",
    "plt.ylim(top=0.3*max(weights))\n",
    "plt.title('Weights of Lasso model for each feature')\n",
    "plt.ylabel('Weight')\n",
    "plt.xlabel('Feature')\n",
    "_ = plt.xticks(ticks=range(len(cols)), labels=cols, rotation=90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# select columns with non-zero weight score\n",
    "cols_important = [col for i, col in enumerate(cols) if weights[i]]\n",
    "print('Selected columns: ', cols_important)\n",
    "cols_to_exclude = list(set(cols) - set(cols_important))\n",
    "print('Excluded columns: ', cols_to_exclude)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The feature 'dropped_frames_max' can be dropped."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = X_train.drop(cols_to_exclude, axis=1)\n",
    "X_test = X_test.drop(cols_to_exclude, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further feature selection can be performed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# calculate mutual inf scores\n",
    "mi = mutual_info_regression(X_train_scaled, y_train)\n",
    "mutual_info = pd.Series(mi, index=X_train.columns)\n",
    "\n",
    "# visualize\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(10, 4))\n",
    "plt.title('Mutual information of features with target')\n",
    "plt.ylabel('Mutual information score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select features based on their mutual information score with target:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "mi_selector = SelectKBest(mutual_info_regression, k=6)\n",
    "mi_selector.fit(X_train_scaled, y_train)\n",
    "mi_selected_feats = X_train.columns[mi_selector.get_support()]\n",
    "print('Selected features based on mutual information: ', mi_selected_feats.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature importance to the model can be obtained by comparing scores from training with dataset including this feature or without it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV, RFE\n",
    "\n",
    "rfe = RFE(\n",
    "    estimator=Lasso(),\n",
    "    step=1,\n",
    "    n_features_to_select=2\n",
    ")\n",
    "\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Ranked features: ')\n",
    "print(pd.Series(X_train.columns[rfe.ranking_.argsort()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This process can be done iteratively with cross validation considering every combination of features and saving the best match."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=Lasso(),\n",
    "    step=2,\n",
    "    cv=5,\n",
    "    min_features_to_select=2\n",
    ")\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "print('Selected features: ', X_train.columns[rfecv.support_].tolist())\n",
    "print('Dropped features: ', set(X_train.columns) - set(X_train.columns[rfecv.support_]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All methods agree that dropped_frames features can be excluded without major performance drop. Besides, these columns are mostly zeros. Deleting features helps to"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_cols = X_train.columns[rfecv.support_].tolist()\n",
    "print('Final selected columns: ', selected_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root of Mean Squared Error\n",
    "    :param y_true: ground truth values\n",
    "    :param y_pred: predicted values\n",
    "    :return: rmse score\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def get_regr_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculation of regression metrics\n",
    "    :param y_true: ground truth values\n",
    "    :param y_pred: predicted values\n",
    "    :return: pd.Series of metric values\n",
    "    \"\"\"\n",
    "    metrics = {'MSE': mean_squared_error(y_true, y_pred), \n",
    "              'RMSE':rmse(y_true, y_pred),\n",
    "              'MAE':mean_absolute_error(y_true, y_pred),\n",
    "               'R2':r2_score(y_true, y_pred)}\n",
    "    \n",
    "    return pd.Series(metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit_predict(model, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Function to perform train and predict\n",
    "    :param model: model to use\n",
    "    :param X_train: train data\n",
    "    :param y_train: target\n",
    "    :param X_test: test data\n",
    "    :return: predicted values for train and test data\n",
    "    \"\"\"\n",
    "    y_pred_train = model.fit_predict(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)    \n",
    "    return y_pred_train, y_pred_test\n",
    "\n",
    "def print_metrics(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"\n",
    "    Function to get train and test metrics\n",
    "    :param y_train: ground truth for train data\n",
    "    :param y_pred_train: predicted values for train data\n",
    "    :param y_test: ground truth for test data\n",
    "    :param y_pred_test: predicted values for test data\n",
    "    :return: DataFrame with train and test metrics\n",
    "    \"\"\"\n",
    "    train_metrics = get_regr_metrics(y_train, y_pred_train)\n",
    "    test_metrics = get_regr_metrics(y_test, y_pred_test)\n",
    "    return pd.concat([train_metrics, test_metrics], axis=1, keys=['train', 'test']).round(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Baseline is training linear regression over all initial features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_regr = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_regr.fit(X_train, y_train)\n",
    "y_train_pred = linear_regr.predict(X_train)\n",
    "y_test_pred = linear_regr.predict(X_test)\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Traininng linear model on selected features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_regr.fit(X_train[selected_cols], y_train)\n",
    "y_train_pred = linear_regr.predict(X_train[selected_cols])\n",
    "y_test_pred = linear_regr.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance did not drop much, but there are less number of predictors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " - Models with regularization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "regr_lasso = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', Lasso())\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(regr_lasso, {'model__alpha':uniform(loc=0, scale=1)}, \n",
    "                                 scoring='r2')\n",
    "search_tool.fit(X_train[selected_cols], y_train)\n",
    "print('Best parameter value alpha = ', search_tool.best_params_['model__alpha'], '\\n')\n",
    "print('Best score: ', search_tool.best_score_)\n",
    "\n",
    "regr_lasso['model'].alpha = search_tool.best_params_['model__alpha']\n",
    "\n",
    "regr_lasso.fit(X_train[selected_cols], y_train)\n",
    "y_train_pred = regr_lasso.predict(X_train[selected_cols])\n",
    "y_test_pred = regr_lasso.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr_ridge = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(regr_ridge, {'model__alpha':uniform(loc=0, scale=1)}, \n",
    "                                 scoring='r2')\n",
    "search_tool.fit(X_train[selected_cols], y_train)\n",
    "print('Best parameter value alpha = ', search_tool.best_params_['model__alpha'], '\\n')\n",
    "print('Best score: ', search_tool.best_score_)\n",
    "\n",
    "regr_ridge['model'].alpha = search_tool.best_params_['model__alpha']\n",
    "\n",
    "regr_ridge.fit(X_train[selected_cols], y_train)\n",
    "y_train_pred = regr_ridge.predict(X_train[selected_cols])\n",
    "y_test_pred = regr_ridge.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Polynomial Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "reg_poly_ridge = Pipeline([\n",
    "    ('poly', PolynomialFeatures()), \n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(reg_poly_ridge, {'model__alpha':uniform(loc=0, scale=1),\n",
    "                                                      'poly__degree':[1, 2, 3]}, \n",
    "                                 scoring='r2')\n",
    "search_tool.fit(X_train[selected_cols], y_train)\n",
    "print('Best parameter value alpha = ', search_tool.best_params_['model__alpha'], '\\n')\n",
    "print('Degree: ', search_tool.best_params_['poly__degree'], '\\n')\n",
    "print('Best score: ', search_tool.best_score_)\n",
    "\n",
    "reg_poly_ridge['model'].alpha = search_tool.best_params_['model__alpha']\n",
    "reg_poly_ridge['poly'].degree = search_tool.best_params_['poly__degree']\n",
    "\n",
    "reg_poly_ridge.fit(X_train[selected_cols], y_train)\n",
    "y_train_pred = reg_poly_ridge.predict(X_train[selected_cols])\n",
    "\n",
    "y_test_pred = reg_poly_ridge.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interaction_regr = Pipeline([\n",
    "    ('interaction', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', Lasso(0.001))\n",
    "])\n",
    "\n",
    "interaction_regr.fit(X_train[selected_cols], y_train)\n",
    "y_train_pred = interaction_regr.predict(X_train[selected_cols])\n",
    "y_test_pred = interaction_regr.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outlier detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear models are highly affected by the outliers. As there is no assumption of normal distribution in given data, interquartile range method can be used to detect them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iqr = X_train[selected_cols].quantile(0.75) - X_train[selected_cols].quantile(0.25)\n",
    "up_bound = X_train[selected_cols].quantile(0.75) + iqr * 1.5\n",
    "low_bound = X_train[selected_cols].quantile(0.25) - iqr * 1.5\n",
    "outliers_mask = ((X_train[selected_cols] > up_bound) | (X_train[selected_cols] < low_bound)).sum(axis=1) > 0\n",
    "X_train_clean = X_train[~outliers_mask][selected_cols].copy()\n",
    "y_train_clean = y_train[~outliers_mask].copy()\n",
    "\n",
    "print('Percentage of outliers: ', 1 - X_train_clean.shape[0] / X_train.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data distribution and paired scatter plots after removing outliers:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(X_train_clean.assign(target=y_train_clean))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no linear correlation in the new features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_ridge = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "search_tool = RandomizedSearchCV(reg_ridge, {'model__alpha':uniform(loc=0, scale=1)}, \n",
    "                                 scoring='r2')\n",
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "print('Best parameter value alpha = ', search_tool.best_params_['model__alpha'], '\\n')\n",
    "print('Best score: ', search_tool.best_score_)\n",
    "reg_poly_ridge['model'].alpha = search_tool.best_params_['model__alpha']\n",
    "\n",
    "reg_poly_ridge.fit(X_train_clean, y_train_clean)\n",
    "y_train_pred = reg_poly_ridge.predict(X_train_clean)\n",
    "\n",
    "y_test_pred = reg_poly_ridge.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train_clean, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removing outliers hurt performance of a model, indicating that useful information was deleted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As another approach, density based methods can be used:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train[selected_cols])\n",
    "outliers_mask = yhat == -1\n",
    "\n",
    "vals, counts = np.unique(yhat, return_counts=True)\n",
    "print('Percentage of outliers: ', counts[0] / train_data.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_clean = X_train[selected_cols][~outliers_mask]\n",
    "y_train_clean = y_train[~outliers_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(X_train_clean.assign(target=y_train_clean))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_tool.fit(X_train_clean, y_train_clean)\n",
    "print('Best parameter value alpha = ', search_tool.best_params_['model__alpha'], '\\n')\n",
    "print('Degree: ', search_tool.best_params_['poly__degree'], '\\n')\n",
    "reg_poly_ridge['model'].alpha = search_tool.best_params_['model__alpha']\n",
    "reg_poly_ridge['poly'].degree = search_tool.best_params_['poly__degree']\n",
    "\n",
    "reg_poly_ridge.fit(X_train_clean, y_train_clean)\n",
    "y_train_pred = reg_poly_ridge.predict(X_train_clean)\n",
    "\n",
    "y_test_pred = reg_poly_ridge.predict(X_test[selected_cols])\n",
    "\n",
    "print_metrics(y_train_clean, y_train_pred, y_test, y_test_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Outlier detection hurts the performance of model. Perhaps there are different methods or the distribution is just too wide."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}